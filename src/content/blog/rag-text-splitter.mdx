---
title: "RAG Text Splitter"
date: 2024-04-16
description: "Text Splitting For Retrieval"
published: true
---

# Text Splitter

## Why

- LLM 对于 Context 有大小限制 (Context Limit)

  > 给的太少

  例如 `gpt-4-1106-preview` Context Window 大小是 128,000 tokens

- 太多数据会带来噪音 (Singal to Nosie)

  > 给的不对

## What

> what is the optimal way for me to pass data my LLM needs for the task

你的目标是不是为了切分数据, 而是规范化数据, 从而更好的被 LLM retrieve

## How

- evaluation

  - [ragas](https://github.com/explodinggradients/ragas)

- 五个级别

  - level 1 字符分隔

        - 基本概念

          [ChunkViz](https://github.com/gkamradt/ChunkViz) 用可视化的方式解释了 以下概念

          - Chunk Size
          - Chunk Overlap
          - seperator

        - 范例

          ```python
            # Create a list that will hold your chunks
            chunks = []

            chunk_size = 35 # Characters

            # Run through the a range with the length of your text and iterate every chunk_size you want
            for i in range(0, len(text), chunk_size):
              chunk = text[i:i + chunk_size]
              chunks.append(chunk)
            chunks
          ```

         - Llama Index

          - documents 对象
          - text node 对象
            - 包含元数据信息
              - Index
              - File Name
              - **Relationship**

- level2 递归字符分隔

  > 第一个级别的问题在于 没有考虑文档的结构

  - 基本概念

    - 通过指定分隔符, 递归的切分文档

    - 通过增加 chunk 的大小 基本可以实现 按段落切分

  - 范例

    ```python
      from langchain.text_splitter import RecursiveCharacterTextSplitter

      text = """

      """

      text_splitter = RecursiveCharacterTextSplitter(chunk_size = 65, chunk_overlap=0)

      text_splitter.create_documents([text])

    ```

  - 增加 chunk 的大小

    - 通过增加 chunk 的大小, 可以实现按段落切分

    - 通过增加 chunk 的大小, 可以实现按句子切分

- level3 指定文档类型

  > 这个级别的文档本身就带有结构信息

  - markdown

    [源代码 js 版本](https://github.com/langchain-ai/langchainjs/blob/main/langchain/src/text_splitter.ts#L590) 列出了所有的分隔符

    - 初始化的 `chunk_size` 可以在 2000, 4000, 5000, 6000. 随着上下文限制的增加, chunk_size 也会增加

  - pdf

    - [unstructured](https://unstructured.io/)

      > cool

      - 转化为 narrative text (不是 documents)

        - 可以识别出 table

          - 转成 HTML 方便 LLM 处理

      - 多模态

        - 可以识别 图片

          - 图片文字总结

            - 图片 转化为 base64
            - `gpt-4-vision-preview` 识别图片文字

- level4 语义化分隔 (Semantic Chunking)

  > - 前三个级别都是基于字符的分隔, 也是基于文档的结构, 但是没有考虑到文档的语义
  > - 把文档内容作为分割的依据, 而不是结构
  > - 前三个级别类比成 图书 按册切分, 语义化分隔类比成 按图书的 genre 切分

  - Heirarchical clustering with positional reward

    - 找到 每个句子 和 相邻句子的 距离
    - 通过距离, 找到最优的分割点

- level5 Agentic Chunking

  >

  - proposition

    - 代词替换成名词, 每个句子都有一个主语
